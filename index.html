<html>
<head>
<title>Unpaired Image-to-Image Translation using Adversarial Consistency Loss</title>
<link rel="SHORTCUT ICON" href="favicon.ico"/>
<link href='css/paperstyle.css' rel='stylesheet' type='text/css'>
</head>

<body>

<div class="pageTitle">
    Unpaired Image-to-Image Translation using Adversarial Consistency Loss
  <br>
  <br>
  <span class = "Authors">
      <a href="https://YihaoZhao.github.io/" target="_blank">Yihao Zhao &nbsp; &nbsp;
      <a href="https://warshallrho.github.io" target="_blank">Ruihai Wu &nbsp; &nbsp;
      <a href="https://zsdonghao.github.io/" target="_blank">Hao Dong</a><sup>*</sup> &nbsp; &nbsp;<br>
      
      <i>(*: corresponding author)</i><br><br>
      <a href = "http://english.pku.edu.cn/" target="_blank"> Peking University </a> &nbsp; &nbsp;

      <a href="https://eccv2020.eu" target="_blank"><i>European Conference on Computer Vision (ECCV) 2020</i></a>
  </span>
  </div>
<br>
<div class = "material">
        <a href="https://arxiv.org/abs/2003.04858" target="_blank">[ArXiv Preprint]</a>
        <a href="https://github.com/hyperplane-lab/ACL-GAN" target="_blank">[Code]</a>
        <a href="paper.bib" target="_blank">[BibTex]</a> 
</div>

<div class = "abstractTitle">
  Abstract
  </div>
  <p class = "abstractText">
  Unpaired image-to-image translation is a class of vision problems whose goal is to find the mapping between different image domains using unpaired training data. Cycle-consistency loss is a widely used constraint for such problems. However, due to the strict pixel-level constraint, it cannot perform shape changes, remove large objects, or ignore irrelevant texture. In this paper, we propose a novel adversarial-consistency loss for image-to-image translation. This loss does not require the translated image to be translated back to be a specific source image but can encourage the translated images to retain important features of the source images and overcome the drawbacks of cycle-consistency loss noted above. Our method achieves state-of-the-art results on three challenging tasks: glasses removal, male-to-female translation, and selfie-to-anime translation.
</p>

<div class="abstractTitle">
    Unpaired Image-to-Image Translation
</div>
  <img class = "bannerImage" src="figures/example.png", width="800"><br>
  <table width="800" align="center"><tr><td><p class = "figureTitleText">
              Figure 1. <b>Example results of our ACL-GAN and baselines. </b>
              Our method does not require cycle consistency, so it can bypass unnecessary features. Moreover, with the proposed adversarial-consistency loss, our method can explicitly encourage the generator to maintain the commonalities between the source and target domains.
  </p></td></tr></table>

<div class="abstractTitle">
    Adversarial-Consistency Loss
</div>
  <img class = "bannerImage" src="figures/acl.png", width="800"><br>
  <table width="800" align="center"><tr><td><p class = "figureTitleText">
              Figure 2. <b>The comparison of adversarial-consistency loss and cycle-consistency loss.</b>
              The blue and green rectangles represent image domains S and T, respectively.
              Any point inside a rectangle represents a specific image in that domain.
  </p></td></tr></table>


<div class="abstractTitle">
    Qualitative Results
</div>
  <img class = "bannerImage" src="figures/glass2none.png", width="800"><br>
  <table width="800" align="center"><tr><td><p class = "figureTitleText">
              Figure 3. <b>Comparison against baselines on glasses removal.</b>
  </p></td></tr></table>
  
    <img class = "bannerImage" src="figures/male2female.png", width="800"><br>
    <table width="800" align="center"><tr><td><p class = "figureTitleText">
                Figure 4. <b>Comparison against baselines on male-to-female translation.</b>
    </p></td></tr></table>

  <img class = "bannerImage" src="figures/selfie2anime.png", width="800"><br>
  <table width="800" align="center"><tr><td><p class = "figureTitleText">
              Figure 5. <b>Comparison against baselines on selfie-to-anime translation.</b>
  </p></td></tr></table>


<div class="abstractTitle">
    Quantitative Comparisons
</div>
  <img class = "bannerImage" src="figures/table.png", width="800"><br>
  <table width="800" align="center"><tr><td><p class = "figureTitleText">
              Figure 6. <b>Quantitative Comparisons to Baseline Methods.</b>
              We show quantitative comparisons between our algorithm and the baseline methods.
  </p></td></tr></table>

  <div class = "abstractTitle">
  Acknowledgements
  </div>
  <p class = "abstractText">
  This work was supported by the funding for building AI super-computer prototype from Peng Cheng Laboratory (8201701524), start-up research funds from Peking University (7100602564) and the Center on Frontiers of Computing Studies (7100602567). We would also like to thank Imperial Institute of Advanced Technology for GPU supports.
</p>



</p></td></tr></table>
</body></html>

